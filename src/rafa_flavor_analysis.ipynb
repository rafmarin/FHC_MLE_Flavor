{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rafa's notebook\n",
    "\n",
    "# import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rafmarin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "   Company_ID Characterizing_Flavor\n0           0        Banana Menthol\n1           0        Banana Menthol\n2           0        Banana Menthol\n3           0        Banana Menthol\n4           0        Banana Menthol",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Company_ID</th>\n      <th>Characterizing_Flavor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Banana Menthol</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Banana Menthol</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>Banana Menthol</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>Banana Menthol</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>Banana Menthol</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data using numpy\n",
    "df = pd.read_csv('FlavorData.csv')\n",
    "df.head() # to display the first 5 lines of loaded data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "Spearmint         1839\nCaramel Candy     1598\nSweet Cream       1560\nExtreme Ice       1505\nChocolate Mint    1420\nCotton Candy      1317\nCinnamon          1272\nButter Cream      1272\nBlueberry         1267\nSweetener         1208\nName: Characterizing_Flavor, dtype: int64"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look into the data\n",
    "\n",
    "# size of data\n",
    "# print(df.shape) # (1048575, 2)\n",
    "\n",
    "# number unique flavors\n",
    "# print(len(df['Characterizing_Flavor'].unique())) # 5130\n",
    "\n",
    "# top 10 most common flavors\n",
    "top10flavors = df['Characterizing_Flavor'].value_counts().head(10)\n",
    "top10flavors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafmarin\\AppData\\Local\\Temp/ipykernel_14800/3555295177.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Characterizing_Flavor'] = df['Characterizing_Flavor'].str.replace(r\"(?<=\\w)-(?=\\w)\", \" \")  # Replace dash between words\n",
      "C:\\Users\\rafmarin\\AppData\\Local\\Temp/ipykernel_14800/3555295177.py:9: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['Characterizing_Flavor'] = df['Characterizing_Flavor'].str.replace('|','')\n",
      "C:\\Users\\rafmarin\\AppData\\Local\\Temp/ipykernel_14800/3555295177.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Characterizing_Flavor'] = df['Characterizing_Flavor'].str.replace(r\"\\s+\", \" \") #remove multiple spaces\n"
     ]
    }
   ],
   "source": [
    "# data scrubbing\n",
    "\n",
    "df['Characterizing_Flavor'].fillna(value='Not Found', inplace= True) #sub null values\n",
    "df['Characterizing_Flavor'] = df['Characterizing_Flavor'].str.strip() #remove trailing and leading spaces\n",
    "df['Characterizing_Flavor'] = df['Characterizing_Flavor'].str.replace(r\"(?<=\\w)-(?=\\w)\", \" \")  # Replace dash between words\n",
    "df['Characterizing_Flavor'] = df['Characterizing_Flavor'].str.lower() #normalize case\n",
    "#df['Characterizing_Flavor'] = df['Characterizing_Flavor'].replace(words, regex=True) #fixing some typos\n",
    "df['Characterizing_Flavor'] = df['Characterizing_Flavor'].str.replace(',','')\n",
    "df['Characterizing_Flavor'] = df['Characterizing_Flavor'].str.replace('|','')\n",
    "df['Characterizing_Flavor'] = df['Characterizing_Flavor'].str.replace('-','')\n",
    "df['Characterizing_Flavor'] = df['Characterizing_Flavor'].str.replace(':','')\n",
    "df['Characterizing_Flavor'] = df['Characterizing_Flavor'].str.replace(r'\\s*[/mgl\\d\\s.]+$', '', regex=True) #removes trailing mg,numbers, characters\n",
    "df['Characterizing_Flavor'] = df['Characterizing_Flavor'].str.replace(r\"\\s+\", \" \") #remove multiple spaces"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          banana menthol\n",
      "1          banana menthol\n",
      "2          banana menthol\n",
      "3          banana menthol\n",
      "4          banana menthol\n",
      "                ...      \n",
      "1048570       port royale\n",
      "1048571        mardi gras\n",
      "1048572        mardi gras\n",
      "1048573        mardi gras\n",
      "1048574        mardi gras\n",
      "Name: Characterizing_Flavor, Length: 1048575, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Fix typos\n",
    "replacements = {'mentho':'menthol','cocunut':'coconut','lycehee':'lychee','starwberry':'strawberry', 'srawberry':'strawberry',\n",
    "                'strawberrry':'strawberry', 'stawberry':'strawberry','koconut':'coconut','rocksatar':'rockstar',\n",
    "                'lrishcrea':'irish cream', 'icin':'icing', 'cockt':'cocktail','cocktai':'cocktail','coolmint':'cool mint',\n",
    "                'vream':'cream', 'crea':'cream', 'mallow':'marshmallow','crakcer':'cracker', 'orangey':'orange',\n",
    "                'whiteandbiue':'white and blue', 'watermelond':'watermelon','smoothi':'smoothie','coffe':'coffee',\n",
    "                'cherryb1osso':'cherryblosso','caramel apples':'caramel apple','bllueberry':'blueberry',\n",
    "                'banapanutbread':'banananutbread', 'strawberry and menthol':'strawberry menthol','menthol cotton candy':'cotton candy menthol',\n",
    "                'grizzly apple coo':'grizzly apple','grape fruit':'grapefruit','cirque du salt berries 20mg/ml 2x':'cirque du salt berries',\n",
    "                'cirque du salt berries 50mg/ml 2x':'cirque du salt berries', 'watermelon melon menthol':'watermelon menthol',\n",
    "                'cinnamon roll (la) diy':'cinnamon roll (la)','cinnabunns':'cinnabun','alaska elixirs loaffetti formerly funfetti':'funfetti'\n",
    "               }\n",
    "\n",
    "def replace_all(text, dic):\n",
    "    for i, j in dic.items():\n",
    "        text = re.sub(r\"\\b%s\\b\" % i, j, text) # r\"\\b%s\\b\"% enables replacing by whole word matches only\n",
    "    return text\n",
    "\n",
    "df['Characterizing_Flavor'] = df['Characterizing_Flavor'].apply(lambda x: replace_all(x, replacements))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4776\n"
     ]
    },
    {
     "data": {
      "text/plain": "spearmint         2014\nextreme ice       1855\npumpkin spice     1806\nchocolate mint    1770\nsweet cream       1735\nblueberry         1617\ncaramel candy     1598\ncoffee            1557\ncucumber mint     1551\nsweetener         1442\nName: Characterizing_Flavor, dtype: int64"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It looks like it changed # uniques and top 10! Nice. Let's keep going.\n",
    "print(df.Characterizing_Flavor.nunique())\n",
    "df['Characterizing_Flavor'].value_counts().head(10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "washington cherry                   1\nmelon dew splash                    1\nminty grape                         1\npeach mango paradise                1\npineapple lemonade                  1\nrussian cream                       1\nstrawberry lemon ice                1\npurple cloud                        1\ncali life                           1\nblueberry blast                     1\ncitrus crush                        1\nstrawberry fields                   1\nlychee ice                          1\nnaz                                 1\nsummertime swir                     1\ngum mint                            1\nimperial mix                        1\nblack jack dragon                   1\npound cake                          1\ndenali delight                      1\nblue cotton                         1\nmint ginger lemon                   1\nlouberry                            1\ngrapple                             1\nfunfetti                            1\nfrozen orange juice                 1\ncoconut milk                        1\nlemon mint                          1\nfreeze mint                         1\nctopus irish cream                  1\nfresh mango                         1\nmint menthol                        1\ndragonfruit strawberry              1\nstrawberry blueberry                1\ncherry sour balls                   1\nmango apple orange                  1\nmelon fruit                         1\ncirque du salt berries ice          1\nmelon pineapple banana              1\nmelon ice                           1\ncoconut mint                        1\nboba's bounty salt                  1\nblueberry huckleberry               1\nblueberry crumble                   1\ncucumber watermelon                 1\nclown tears                         1\nbrez battery                        1\nchallenger automatic battery        1\nchallenger manual battery           1\nafter midnight                      1\ncalifornia grape                    1\ncantaloupe ice                      1\nchai ice                            1\nraspberry mango                     1\npineapple ice                       1\nmat su thunder duck                 1\nfruit flakes                        1\ncinnamon fire                       1\nstrawberries & banana's w/ cream    1\nName: Characterizing_Flavor, dtype: int64"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Taking a look at the least common flavors to see if theres anything else we need to scrub\n",
    "df['Characterizing_Flavor'].value_counts(ascending=True).head(59)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "        Company_ID Characterizing_Flavor\n923878          29            snake veno\n923969          29            snake veno\n936703          29            snake veno\n936710          29            snake veno\n936714          29            snake veno\n...            ...                   ...\n937434          29            snake veno\n937438          29            snake veno\n937443          29            snake veno\n937447          29            snake veno\n937451          29            snake veno\n\n[170 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Company_ID</th>\n      <th>Characterizing_Flavor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>923878</th>\n      <td>29</td>\n      <td>snake veno</td>\n    </tr>\n    <tr>\n      <th>923969</th>\n      <td>29</td>\n      <td>snake veno</td>\n    </tr>\n    <tr>\n      <th>936703</th>\n      <td>29</td>\n      <td>snake veno</td>\n    </tr>\n    <tr>\n      <th>936710</th>\n      <td>29</td>\n      <td>snake veno</td>\n    </tr>\n    <tr>\n      <th>936714</th>\n      <td>29</td>\n      <td>snake veno</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>937434</th>\n      <td>29</td>\n      <td>snake veno</td>\n    </tr>\n    <tr>\n      <th>937438</th>\n      <td>29</td>\n      <td>snake veno</td>\n    </tr>\n    <tr>\n      <th>937443</th>\n      <td>29</td>\n      <td>snake veno</td>\n    </tr>\n    <tr>\n      <th>937447</th>\n      <td>29</td>\n      <td>snake veno</td>\n    </tr>\n    <tr>\n      <th>937451</th>\n      <td>29</td>\n      <td>snake veno</td>\n    </tr>\n  </tbody>\n</table>\n<p>170 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Characterizing_Flavor'].astype(str).str.contains('veno', regex = True)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "print(df.Company_ID.nunique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "def tokenize_text(text, tokenizer, stopwords):\n",
    "    tokens = tokenizer(text) # Get tokens from text\n",
    "    tokens = [t for t in tokens if not t in stopwords]  # Remove stopwords\n",
    "    tokens = [t.replace(\"'s\",\"\") for t in tokens] # remove 's\n",
    "    tokens = [t for t in tokens if len(t) > 1]  # Remove short tokens\n",
    "    return tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001B[93mstopwords\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mcorpora/stopwords\u001B[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\rafmarin/nltk_data'\n    - 'c:\\\\users\\\\rafmarin\\\\pycharmprojects\\\\fhc_mle_flavor\\\\venv\\\\nltk_data'\n    - 'c:\\\\users\\\\rafmarin\\\\pycharmprojects\\\\fhc_mle_flavor\\\\venv\\\\share\\\\nltk_data'\n    - 'c:\\\\users\\\\rafmarin\\\\pycharmprojects\\\\fhc_mle_flavor\\\\venv\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\rafmarin\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mLookupError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32mc:\\users\\rafmarin\\pycharmprojects\\fhc_mle_flavor\\venv\\lib\\site-packages\\nltk\\corpus\\util.py\u001B[0m in \u001B[0;36m__load\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     83\u001B[0m                 \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 84\u001B[1;33m                     \u001B[0mroot\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnltk\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfind\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"{self.subdir}/{zip_name}\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     85\u001B[0m                 \u001B[1;32mexcept\u001B[0m \u001B[0mLookupError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\rafmarin\\pycharmprojects\\fhc_mle_flavor\\venv\\lib\\site-packages\\nltk\\data.py\u001B[0m in \u001B[0;36mfind\u001B[1;34m(resource_name, paths)\u001B[0m\n\u001B[0;32m    582\u001B[0m     \u001B[0mresource_not_found\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 583\u001B[1;33m     \u001B[1;32mraise\u001B[0m \u001B[0mLookupError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresource_not_found\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    584\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mLookupError\u001B[0m: \n**********************************************************************\n  Resource \u001B[93mstopwords\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mcorpora/stopwords.zip/stopwords/\u001B[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\rafmarin/nltk_data'\n    - 'c:\\\\users\\\\rafmarin\\\\pycharmprojects\\\\fhc_mle_flavor\\\\venv\\\\nltk_data'\n    - 'c:\\\\users\\\\rafmarin\\\\pycharmprojects\\\\fhc_mle_flavor\\\\venv\\\\share\\\\nltk_data'\n    - 'c:\\\\users\\\\rafmarin\\\\pycharmprojects\\\\fhc_mle_flavor\\\\venv\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\rafmarin\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mLookupError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_14800/1662671317.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m#generate tokens from text in tokens column\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mcustom_stopwords\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstopwords\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwords\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"english\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mtext_columns\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m\"Characterizing_Flavor\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\rafmarin\\pycharmprojects\\fhc_mle_flavor\\venv\\lib\\site-packages\\nltk\\corpus\\util.py\u001B[0m in \u001B[0;36m__getattr__\u001B[1;34m(self, attr)\u001B[0m\n\u001B[0;32m    119\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mAttributeError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    120\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 121\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__load\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    122\u001B[0m         \u001B[1;31m# This looks circular, but its not, since __load() changes our\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    123\u001B[0m         \u001B[1;31m# __class__ to something new:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\rafmarin\\pycharmprojects\\fhc_mle_flavor\\venv\\lib\\site-packages\\nltk\\corpus\\util.py\u001B[0m in \u001B[0;36m__load\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     84\u001B[0m                     \u001B[0mroot\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnltk\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfind\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"{self.subdir}/{zip_name}\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     85\u001B[0m                 \u001B[1;32mexcept\u001B[0m \u001B[0mLookupError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 86\u001B[1;33m                     \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     87\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     88\u001B[0m         \u001B[1;31m# Load the corpus.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\rafmarin\\pycharmprojects\\fhc_mle_flavor\\venv\\lib\\site-packages\\nltk\\corpus\\util.py\u001B[0m in \u001B[0;36m__load\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     79\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     80\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 81\u001B[1;33m                 \u001B[0mroot\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnltk\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfind\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"{self.subdir}/{self.__name}\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     82\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mLookupError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     83\u001B[0m                 \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\rafmarin\\pycharmprojects\\fhc_mle_flavor\\venv\\lib\\site-packages\\nltk\\data.py\u001B[0m in \u001B[0;36mfind\u001B[1;34m(resource_name, paths)\u001B[0m\n\u001B[0;32m    581\u001B[0m     \u001B[0msep\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"*\"\u001B[0m \u001B[1;33m*\u001B[0m \u001B[1;36m70\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    582\u001B[0m     \u001B[0mresource_not_found\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 583\u001B[1;33m     \u001B[1;32mraise\u001B[0m \u001B[0mLookupError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresource_not_found\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    584\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    585\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mLookupError\u001B[0m: \n**********************************************************************\n  Resource \u001B[93mstopwords\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mcorpora/stopwords\u001B[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\rafmarin/nltk_data'\n    - 'c:\\\\users\\\\rafmarin\\\\pycharmprojects\\\\fhc_mle_flavor\\\\venv\\\\nltk_data'\n    - 'c:\\\\users\\\\rafmarin\\\\pycharmprojects\\\\fhc_mle_flavor\\\\venv\\\\share\\\\nltk_data'\n    - 'c:\\\\users\\\\rafmarin\\\\pycharmprojects\\\\fhc_mle_flavor\\\\venv\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\rafmarin\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#generate tokens from text in tokens column\n",
    "\n",
    "custom_stopwords = set(stopwords.words(\"english\"))\n",
    "text_columns = [\"Characterizing_Flavor\"]\n",
    "\n",
    "df_emb = df.copy()\n",
    "df_emb.insert(2,\"tokens\",0)\n",
    "\n",
    "#convert to string\n",
    "for col in text_columns:\n",
    "    df_emb[col] = df_emb[col].astype(str)\n",
    "\n",
    "# tokenize text\n",
    "df_emb[\"tokens\"] = df_emb[\"Characterizing_Flavor\"].map(lambda x: tokenize_text(x, word_tokenize, custom_stopwords))\n",
    "print(df_emb)\n",
    "\n",
    "# Remove duplicated after preprocessing\n",
    "df_emb_uniq = df_emb.copy()\n",
    "_, idx = np.unique(df_emb_uniq[\"tokens\"], return_index=True)\n",
    "df_emb_uniq = df_emb_uniq.iloc[idx, :]\n",
    "\n",
    "# Remove empty values and keep relevant columns\n",
    "df_emb = df_emb.loc[df_emb.tokens.map(lambda x: len(x) > 0), [\"Characterizing_Flavor\",\"tokens\"]]\n",
    "df_emb_uniq = df_emb_uniq.loc[df_emb_uniq.tokens.map(lambda x: len(x) > 0), [\"Characterizing_Flavor\",\"tokens\"]]\n",
    "\n",
    "\n",
    "print(f\"Original dataframe: {df.shape}\")\n",
    "print(f\"Pre-processed dataframe, w duplicates: {df_emb.shape}\")\n",
    "print(f\"Pre-processed dataframe, without duplicates: {df_emb_uniq.shape}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_emb_uniq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_14800/3692399251.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf_emb_uniq\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df_emb_uniq' is not defined"
     ]
    }
   ],
   "source": [
    "print(df_emb_uniq)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenized_docs = df_emb.tokens.tolist()\n",
    "\n",
    "model = Word2Vec(sentences=tokenized_docs, vector_size=100, workers=1, seed=SEED)\n",
    "\n",
    "def vectorize(list_of_docs, model):\n",
    "    \"\"\"Generate vectors for list of documents using a Word Embedding\n",
    "\n",
    "    Args:\n",
    "        list_of_docs: List of documents\n",
    "        model: Gensim's Word Embedding\n",
    "\n",
    "    Returns:\n",
    "        List of document vectors\n",
    "    \"\"\"\n",
    "    features = []\n",
    "\n",
    "    for tokens in list_of_docs:\n",
    "        zero_vector = np.zeros(model.vector_size)\n",
    "        vectors = []\n",
    "        for token in tokens:\n",
    "            if token in model.wv:\n",
    "                try:\n",
    "                    vectors.append(model.wv[token])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        if vectors:\n",
    "            vectors = np.asarray(vectors)\n",
    "            avg_vec = vectors.mean(axis=0)\n",
    "            features.append(avg_vec)\n",
    "        else:\n",
    "            features.append(zero_vector)\n",
    "    return features\n",
    "\n",
    "vectorized_docs = vectorize(tokenized_docs, model=model)\n",
    "\n",
    "## what do these represent? length of the list of documents, size of the generated vectors\n",
    "len(vectorized_docs), len(vectorized_docs[0])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}